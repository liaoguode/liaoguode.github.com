---
layout: post
title:  "spark2学习笔记五"
categories: spark2
tag: spark2学习笔记
---

Shuffle操作
=======
<br />

Spark中的某些操作触发一个名为shuffle的事件。shuffle是Spark重新分发数据的机制，以便在不同的分区之间进行分组。这通常涉及在执行器和驱动程序之间复制数据，从而进行复杂而昂贵的操作。

要了解在Shuffle过程中发生了什么，我们可以参照reduceByKey操作的例子。reduceByKey操作生成一个新的RDD，其中同一个key的所有值被合并成一个元组——key和在该key关联的所有值上执行一个reduce函数的结果。挑战在于，并非所有的值都驻留在同一个partition上，甚至是同一台机器上，但它们必须协作来计算结果。

在Spark中，数据通常不会跨分区分布到特定操作的必要位置。在计算过程中，单个任务将在单个分区上进行操作——因此，为了组织所有的数据以执行单个reduceByKey任务，Spark需要执行所有操作。它必须从所有分区读取所有键的所
虽然每个shuffle后的partition有值，然后将各个分区的值合并到一起来计算每个key的最终结果——这称为shuffle。
