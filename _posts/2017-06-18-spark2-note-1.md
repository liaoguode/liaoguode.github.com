---
layout: post
title:  "spark2学习笔记一"
date:  2017-06-18 20:00:00
categories: spark2
auth: peterliao
tag: 
    - spark2学习笔记
---


spark概念
============
<br />
    
每一个spark应用都是由一个运行用户mian函数，并且同时在spark集群中进行各种并行操作的驱动程序组成。spark最主要的概念是弹性分布式数据集，弹性分布式数据集简称为RDD，RDD是通过spark集群的节点数进行划分的元素集合，如此划分是为了数据能够被并行处理。RDD通过hadoop文件系统HDFS的文件（或者hadoop支持的其他文件系统的文件）来创建，并且也能够通过转化spark应用已经存在的scala集合来创建RDD。用户为了能够在并行操作高效的重复使用某个RDD,可以在内存将其缓存起来，并且RDD能够从故障节点自动恢复。

spark的另外一个重要概念是能够在并行操作中使用的共享变量。一般说来，当spark应用并行运行main函数时，将整个main函数拆分为多个任务分配到各个节点，此时一般都会将main函数中使用到的变量拷贝一份到各个执行任务的节点。有时，需要在任务之间或任务和驱动程序之间共享一个变量。Spark支持两种类型的共享变量：广播变量，用来缓存在所有节点的内存中的值，广播变量是只读变量。累加器，它们只是用来累加，诸如计数器和求和变量，累加器在节点上可以累加，但是它的值只有在驱动程序中可以获取到。